# üéì Master in Big Data & Cloud ‚Äì My Learning Journey üåü
Hey there! üëã Welcome to my personal repository for **the Master's Big Data & Cloud at EDEM** (Valencia, Spain). Here, I‚Äôve organized everything I‚Äôve learned into modules, with hands-on assignments, notes, and projects as I progress through the course.

> üöß **This repository is still a work in progress** ‚Äî I‚Äôll keep uploading and updating it with new content as I go!

> üìå **Note**: I haven‚Äôt uploaded all of my assignments and notes. Some are fairly basic, while others are directly designed by my professors. To ensure the integrity of the work and focus on what I‚Äôve personally developed, I‚Äôve only shared the assignments and projects I consider most relevant for this repository.

## üìö Repository Structure
The repository is organized into several folders to keep the content structured and easy to navigate.<br>
In each folder, you will find a **README.md** that explains in more detail what I have learned, along with descriptions of its content and **subfolders** for each tool/concept. Inside these subfolders, you can explore my most relevant assignments and notes (notes are only included in Module 1).

### üì¶ [Module 1 ‚Äì Fundamentals](MODULE_1) 
This module laid the foundation for working in data and cloud environments. It focused on understanding how to navigate and work with **Linux** systems, use version control with **GitHub**, write Python code, containerize applications with **Docker**, and manage data using **SQL**.

### ‚öôÔ∏è [Module 2 ‚Äì Data Processing](MODULE_2)
This module introduced how to work with data pipelines and processing frameworks. The goal was to learn how to **ingest, transform, and analyze** data from multiple sources in **real time or batch**. It covered both structured and unstructured data, and introduced key data engineering workflows.

### ‚òÅÔ∏è [Module 3 ‚Äì Cloud](MODULE_3)
The focus here was to design and deploy scalable solutions using cloud platforms like **GCP, AWS, and Azure**. We also learned how to automate infrastructure management using **Terraform** and apply CI/CD principles with **GitHub Actions**. Most cloud assignments used Terraform for reproducibility and scalability.

### [Data Projects](DATA_PROJECTS)
A separate folder dedicated to more advanced projects, showcasing larger-scale work involving multiple tools and technologies. These projects go beyond individual assignments and explore real-world applications. Here is a brief description of each!:
- **Data Project 1**: Developed a fully dockerized on-premise data pipeline that integrated APIs for data ingestion, used Python for transformation, and stored the processed data in PostgreSQL. Built an interactive UI with Streamlit to visualize and interact with the data.
- **Data Project 2**: Designed and deployed a fully cloud-based platform on GCP using Terraform. The application connects individuals affected by the DANA in Valencia with volunteers. It automates the matching process based on location, type of aid, and urgency, optimizing resource distribution and response times. The system leverages GCP services for data processing, storage, and scalability.
- **Data/AI Project 3**: Designed and deployed a fully cloud-based application on GCP using Terraform. We created BetMaestro, a smart assistant that helps users make informed decisions when betting on NBA games. The chatbot leverages real-time data and predictive models to deliver insights and recommendations. It is a fully integrated end to end solution that gathers and processes data from multiple sports-related APIs, runs predictive models, and serves insights through a conversational interface.

---

Feel free to explore the modules and see what I've been up to! üå± 

